# ğŸ¤– Pawnear - Multi-Site Scraper

GÃ¼nde bir kez otomatik olarak Ã§alÄ±ÅŸan, kayÄ±p/sahiplendirme ilanlarÄ±nÄ± tarayan modÃ¼ler Python scraper.

## ğŸŒ Desteklenen Siteler

1. âœ… **GorenDuyan.com** - KayÄ±p/Bulundu (Kedi & KÃ¶pek)
2. âœ… **Petcim.com** - SatÄ±lÄ±k (Kedi & KÃ¶pek)
3. âœ… **Petlebi.com** - Sahiplendirme (Kedi & KÃ¶pek)

**Toplam:** 3 site Ã— 2 kategori = 6 veri kaynaÄŸÄ±

## ğŸ› ï¸ Ã–zellikler

- ğŸ”„ ModÃ¼ler yapÄ± - Yeni siteler kolayca eklenebilir
- ğŸ¤– CloudScraper - Bot korumasÄ±nÄ± aÅŸar
- ğŸ“… Otomatik tarih filtreleme (son 24 saat)
- ğŸš« Duplikasyon Ã¶nleme
- ğŸ“± Telegram bildirimleri
- â° GitHub Actions ile gÃ¼nlÃ¼k otomatik Ã§alÄ±ÅŸma (09:00 UTC)
- ğŸ”„ Rate limiting ve retry mekanizmasÄ±
- ğŸ“ Tarihli dosya sistemi (gÃ¼nlÃ¼k arÅŸiv)

## ğŸ“¦ Kurulum

```bash
pip install -r requirements.txt
```

## ğŸš€ KullanÄ±m

### Lokal Ã‡alÄ±ÅŸtÄ±rma
```bash
python github_scraper.py
```

### GitHub Actions (Otomatik)
Her gÃ¼n 09:00 UTC (12:00 TR)'de otomatik Ã§alÄ±ÅŸÄ±r ve:
- Tarihli JSON oluÅŸturur: `data/ilan_taramasi_2025-11-22.json`
- Son durumu gÃ¼nceller: `data/ilanlar.json`
- Telegram'dan bildirim gÃ¶nderir

## ğŸ“ Ã‡Ä±ktÄ± FormatÄ±

```json
[
  {
    "ilan_turu": "KayÄ±p",
    "baslik": "...",
    "aciklama": "...",
    "konum": "Ä°l / Ä°lÃ§e",
    "tarih1": "2 Saat Ã–nce",
    "tarih2": "2025-11-22T14:00:00Z",
    "kategori": "Kedi",
    "gorsel": "https://...",
    "link": "https://..."
  }
]
```

## â• Yeni Site Ekleme

1. `scrapers/` klasÃ¶rÃ¼ne yeni scraper ekle
2. `BaseScraper` sÄ±nÄ±fÄ±ndan tÃ¼ret
3. Gerekli metodlarÄ± implement et
4. `scraper_manager.py`'ye ekle

```python
# scrapers/yenisite_scraper.py
from .base_scraper import BaseScraper

class YeniSiteScraper(BaseScraper):
    def __init__(self):
        super().__init__("YeniSite")
        self.base_url = "https://yenisite.com"
    
    def scrape(self) -> List[Dict]:
        # Site-spesifik scraping mantÄ±ÄŸÄ±
        pass
    
    def parse_listings(self, soup, kategori: str) -> List[Dict]:
        # HTML parse mantÄ±ÄŸÄ±
        pass
    
    def extract_details(self, ad: Dict) -> Dict:
        # Detay sayfasÄ± mantÄ±ÄŸÄ±
        pass
```

## ğŸ“Š Proje YapÄ±sÄ±

```
scrapers/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base_scraper.py         # Abstract base class
â”œâ”€â”€ cloud_scraper.py        # CloudScraper (bot bypass)
â”œâ”€â”€ gorenduyan_scraper.py   # GorenDuyan implementasyonu
â”œâ”€â”€ petcim_scraper.py       # Petcim implementasyonu
â”œâ”€â”€ petlebi_scraper.py      # Petlebi implementasyonu
â””â”€â”€ scraper_manager.py      # Scraper orchestrator

github_scraper.py            # Ana script
send_telegram.py             # Telegram bildirimi
requirements.txt             # BaÄŸÄ±mlÄ±lÄ±klar
```

## ğŸ” GitHub Secrets

Gerekli secrets:
- `TELEGRAM_BOT_TOKEN` - Bot token
- `TELEGRAM_CHAT_ID` - Chat ID
- `GITHUB_TOKEN` - Otomatik saÄŸlanÄ±r

## ğŸ“ Lisans

MIT

---

ğŸ¾ Made with â¤ï¸ for lost pets
